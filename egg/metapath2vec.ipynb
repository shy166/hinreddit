{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from torch_geometric.nn import MetaPath2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import io\n",
    "from torch_geometric.utils import from_scipy_sparse_matrix\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# graph 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = io.loadmat('/datasets/dsc180a-wi20-public/Malware/group_data/group_02/sensitive_data/interim/graph/graph_1.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_user = from_scipy_sparse_matrix(g['U'])\n",
    "author_post = from_scipy_sparse_matrix(g['A'])\n",
    "post_user = from_scipy_sparse_matrix(g['P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103413"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g['post_indx'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(\n",
    "    edge_index_dict = {\n",
    "        ('user', 'replied by', 'user') : user_user[0],\n",
    "        ('user', 'wrote', 'post') : author_post[0],\n",
    "        ('post', 'commented by', 'user') : post_user[0],\n",
    "    },\n",
    "    num_nodes_dict = {\n",
    "        'post': g['post_indx'].shape[1],\n",
    "        'user' : g['user_indx'].shape[1]\n",
    "    },\n",
    "    y_dict = {\n",
    "        'post': torch.from_numpy(g['post_label'].reshape(-1,)).long()\n",
    "    },\n",
    "    x_dict = {\n",
    "        'post': torch.from_numpy(g['post_cate']).float()\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metapath = [\n",
    "    ('post', 'commented by', 'user'),\n",
    "    ('user', 'replied by', 'user'),\n",
    "    ('user', 'wrote', 'post')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MetaPath2Vec(data.edge_index_dict, embedding_dim=128,\n",
    "                     metapath=metapath, walk_length=50, context_size=7,\n",
    "                     walks_per_node=5, num_negative_samples=5,\n",
    "                     sparse=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = model.loader(batch_size=16, shuffle=False, num_workers=8)\n",
    "optimizer = torch.optim.SparseAdam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loading = iter(loader)\n",
    "counter = 0\n",
    "while tmp != None:\n",
    "    prev = tmp\n",
    "    try:\n",
    "        tmp = next(loading)\n",
    "    except IndexError:\n",
    "        continue\n",
    "    except StopIteration:\n",
    "        tmp = None\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6465"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[103408, 214320, 107165,  ..., 539621, 446463,  43523],\n",
       "         [103409, 199599, 571074,  ..., 474440, 288318,  75412],\n",
       "         [103410, 355714, 486876,  ..., 234713, 560888,  89601],\n",
       "         ...,\n",
       "         [278157,  15491, 536311,  ...,  78628, 142000, 154703],\n",
       "         [576989,   5994, 209205,  ...,   3186, 140329, 226872],\n",
       "         [256241,   2591, 411321,  ...,   4737, 411321, 214266]]),\n",
       " tensor([[103408, 146529, 402927,  ..., 153844, 251162,  49938],\n",
       "         [103409, 551784, 381513,  ..., 537641, 485434,  45425],\n",
       "         [103410, 307983, 246372,  ..., 200748, 451944,  77453],\n",
       "         ...,\n",
       "         [257165,    595, 212398,  ...,  73577, 564333, 464584],\n",
       "         [320349,  34090, 199319,  ...,  26163, 218989, 373654],\n",
       "         [517312,  57033, 575295,  ...,  10769, 449020, 438912]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, log_steps=100, eval_steps=2000):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for i, (pos_rw, neg_rw) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if (i + 1) % log_steps == 0:\n",
    "            print((f'Epoch: {epoch}, Step: {i + 1:05d}/{len(loader)}, '\n",
    "                   f'Loss: {total_loss / log_steps:.4f}'))\n",
    "            total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Step: 00100/6464, Loss: 9.7041\n",
      "Epoch: 1, Step: 00200/6464, Loss: 9.0075\n",
      "Epoch: 1, Step: 00300/6464, Loss: 8.3603\n",
      "Epoch: 1, Step: 00400/6464, Loss: 7.7983\n",
      "Epoch: 1, Step: 00500/6464, Loss: 7.3316\n",
      "Epoch: 1, Step: 00600/6464, Loss: 6.9026\n",
      "Epoch: 1, Step: 00700/6464, Loss: 6.4879\n",
      "Epoch: 1, Step: 00800/6464, Loss: 6.1329\n",
      "Epoch: 1, Step: 00900/6464, Loss: 5.8208\n",
      "Epoch: 1, Step: 01000/6464, Loss: 5.4998\n",
      "Epoch: 1, Step: 01100/6464, Loss: 5.2193\n",
      "Epoch: 1, Step: 01200/6464, Loss: 4.9503\n",
      "Epoch: 1, Step: 01300/6464, Loss: 4.6946\n",
      "Epoch: 1, Step: 01400/6464, Loss: 4.4528\n",
      "Epoch: 1, Step: 01500/6464, Loss: 4.2330\n",
      "Epoch: 1, Step: 01600/6464, Loss: 4.0273\n",
      "Epoch: 1, Step: 01700/6464, Loss: 3.8290\n",
      "Epoch: 1, Step: 01800/6464, Loss: 3.6388\n",
      "Epoch: 1, Step: 01900/6464, Loss: 3.4611\n",
      "Epoch: 1, Step: 02000/6464, Loss: 3.3034\n",
      "Epoch: 1, Step: 02100/6464, Loss: 3.1654\n",
      "Epoch: 1, Step: 02200/6464, Loss: 3.0243\n",
      "Epoch: 1, Step: 02300/6464, Loss: 2.9031\n",
      "Epoch: 1, Step: 02400/6464, Loss: 2.7898\n",
      "Epoch: 1, Step: 02500/6464, Loss: 2.6926\n",
      "Epoch: 1, Step: 02600/6464, Loss: 2.5933\n",
      "Epoch: 1, Step: 02700/6464, Loss: 2.5062\n",
      "Epoch: 1, Step: 02800/6464, Loss: 2.4264\n",
      "Epoch: 1, Step: 02900/6464, Loss: 2.3478\n",
      "Epoch: 1, Step: 03000/6464, Loss: 2.2797\n",
      "Epoch: 1, Step: 03100/6464, Loss: 2.2197\n",
      "Epoch: 1, Step: 03200/6464, Loss: 2.1484\n",
      "Epoch: 1, Step: 03300/6464, Loss: 2.0915\n",
      "Epoch: 1, Step: 03400/6464, Loss: 2.0370\n",
      "Epoch: 1, Step: 03500/6464, Loss: 1.9885\n",
      "Epoch: 1, Step: 03600/6464, Loss: 1.9435\n",
      "Epoch: 1, Step: 03700/6464, Loss: 1.8959\n",
      "Epoch: 1, Step: 03800/6464, Loss: 1.8541\n",
      "Epoch: 1, Step: 03900/6464, Loss: 1.8065\n",
      "Epoch: 1, Step: 04000/6464, Loss: 1.7717\n",
      "Epoch: 1, Step: 04100/6464, Loss: 1.7313\n",
      "Epoch: 1, Step: 04200/6464, Loss: 1.6957\n",
      "Epoch: 1, Step: 04300/6464, Loss: 1.6596\n",
      "Epoch: 1, Step: 04400/6464, Loss: 1.6352\n",
      "Epoch: 1, Step: 04500/6464, Loss: 1.6020\n",
      "Epoch: 1, Step: 04600/6464, Loss: 1.5767\n",
      "Epoch: 1, Step: 04700/6464, Loss: 1.5478\n",
      "Epoch: 1, Step: 04800/6464, Loss: 1.5258\n",
      "Epoch: 1, Step: 04900/6464, Loss: 1.5028\n",
      "Epoch: 1, Step: 05000/6464, Loss: 1.4790\n",
      "Epoch: 1, Step: 05100/6464, Loss: 1.4555\n",
      "Epoch: 1, Step: 05200/6464, Loss: 1.4359\n",
      "Epoch: 1, Step: 05300/6464, Loss: 1.4158\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-02192c450a1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {epoch}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-98283d614bbb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, log_steps, eval_steps)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_rw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_rw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/sparse_adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoalesce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# the update is non-linear so indices must be unique\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                 \u001b[0mgrad_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mgrad_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 5):\n",
    "    train(epoch)\n",
    "    print(f'Epoch: {epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2263, -0.2811, -0.1195,  ..., -0.0130, -0.0995,  0.4083],\n",
       "        [-0.0524, -0.2548,  0.0232,  ..., -0.0941, -0.1302,  0.0568],\n",
       "        [ 0.1766,  0.2105,  0.4731,  ...,  0.2764, -0.1551, -0.0673],\n",
       "        ...,\n",
       "        [ 0.0261, -0.0148, -0.0330,  ..., -0.1629,  0.3715, -0.0166],\n",
       "        [-0.1730, -0.0090,  0.1922,  ..., -0.3166,  0.2244, -0.2501],\n",
       "        [-0.3542, -0.3214, -0.3340,  ..., -0.4198,  0.2730,  0.1638]],\n",
       "       device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model('post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
